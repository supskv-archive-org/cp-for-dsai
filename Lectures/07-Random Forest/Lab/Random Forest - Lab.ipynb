{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the Bagging scratch code in our lecture such that:\n",
    "- Calculate for oob evaluation for each bootstrapped dataset, and also the average score\n",
    "- Change the code to \"without replacement\"\n",
    "- Put everything into a class <code>Bagging</code>.  It should have at least two methods, <code>fit(X_train, y_train)</code>, and <code>predict(X_test)</code>\n",
    "- Modify the code from above to randomize features.  Set the number of features to be used in each tree to be <code>sqrt(n)</code>, and then select a subset of features for each tree.  This can be easily done by setting our DecisionTreeClassifier <code>max_features</code> to 'sqrt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                test_size=0.3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import random\n",
    "from scipy import stats\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bagging:\n",
    "    def __init__(self, B, boostrap_ratio, without_replacement=True):\n",
    "        self.B = B\n",
    "        self.boostrap_ratio = boostrap_ratio\n",
    "        self.without_replacement = without_replacement\n",
    "        self.tree_params = {'max_depth': 2, 'criterion':'gini', 'min_samples_split': 5, 'max_features': 'sqrt'}\n",
    "        self.models = [DecisionTreeClassifier(**self.tree_params) for _ in range(B)]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        #sample size for each tree\n",
    "        B = self.B\n",
    "        m, n = X.shape\n",
    "        sample_size = int(self.boostrap_ratio * len(X))\n",
    "\n",
    "        xsamples = np.zeros((B, sample_size, n))\n",
    "        ysamples = np.zeros((B, sample_size))\n",
    "        \n",
    "        xsamples_oob = []\n",
    "        ysamples_oob = []\n",
    "        \n",
    "        #subsamples for each model\n",
    "        for i in range(B):\n",
    "            oob_idx = []\n",
    "            idxes = []\n",
    "            ##sampling with replacement; i.e., sample can occur more than once\n",
    "            #for the same predictor\n",
    "            for j in range(sample_size):\n",
    "                idx = random.randrange(m)   #<----with replacement #change so no repetition\n",
    "                if (self.without_replacement):\n",
    "                    while idx in idxes:\n",
    "                        idx = random.randrange(m)\n",
    "                oob_idx.append(idx)\n",
    "                idxes.append(idx)\n",
    "                xsamples[i, j, :] = X_train[idx]\n",
    "                ysamples[i, j] = y_train[idx]\n",
    "                #keep track of idx that i did not use for ith tree\n",
    "            mask = np.zeros((m), dtype=bool)\n",
    "            mask[oob_idx] = True\n",
    "            xsamples_oob.append(X[~mask])\n",
    "            ysamples_oob.append(y[~mask])\n",
    "\n",
    "        #fitting each estimator\n",
    "        oob_scores = []\n",
    "        for i, model in enumerate(self.models):\n",
    "            _X = xsamples[i, :]\n",
    "            _y = ysamples[i, :]\n",
    "            model.fit(_X, _y)\n",
    "            \n",
    "            _X_test = np.asarray(xsamples_oob[i])\n",
    "            _y_test = np.asarray(ysamples_oob[i])\n",
    "            yhat = model.predict(_X_test)\n",
    "            oob_score = accuracy_score(_y_test, yhat)\n",
    "            oob_scores.append(oob_score)\n",
    "        self.oob_scores = np.array(oob_scores)\n",
    "        self.avg_oob_score = self.oob_scores.sum() / len(self.models)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros((self.B, X.shape[0]))\n",
    "        for i, model in enumerate(self.models):\n",
    "            yhat = model.predict(X)\n",
    "            predictions[i, :] = yhat\n",
    "\n",
    "        yhat = stats.mode(predictions)[0][0]\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Bagging(B=5, boostrap_ratio=0.8)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test)\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of Bag scores:\n",
      "Model 1: 0.9047619047619048\n",
      "Model 2: 0.9047619047619048\n",
      "Model 3: 0.9047619047619048\n",
      "Model 4: 0.9523809523809523\n",
      "Model 5: 0.9047619047619048\n",
      "Average Out of bag score: 0.9142857142857144\n"
     ]
    }
   ],
   "source": [
    "print(\"Out of Bag scores:\")\n",
    "for i, score in enumerate(model.oob_scores): print(f\"Model {i+1}: {score}\")\n",
    "print(\"Average Out of bag score:\", model.avg_oob_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 2, 'n_estimators': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#this is the same as RandomForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\"n_estimators\": [10, 50, 100], \n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"max_depth\": np.arange(1, 10)}\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "grid = GridSearchCV(model, param_grid)\n",
    "grid.fit(X, y)\n",
    "\n",
    "print(grid.best_params_)\n",
    "\n",
    "model = grid.best_estimator_\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
