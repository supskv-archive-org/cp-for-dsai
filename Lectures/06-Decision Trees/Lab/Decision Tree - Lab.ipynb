{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the Decision Tree scratch code in our lecture such that:\n",
    "- Modify the scratch code so it can accept an hyperparameter <code>max_depth</code>, in which it will continue create the tree until max_depth is reached.</li>\n",
    "- Put everything into a class <code>DecisionTree</code>.  It should have at least two methods, <code>fit()</code>, and <code>predict()</code>\n",
    "- Load the iris data and try with your class</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, gini, num_samples, num_samples_per_class, predicted_class):\n",
    "        self.gini = gini\n",
    "        self.num_samples = num_samples\n",
    "        self.num_samples_per_class = num_samples_per_class\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        \n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def find_split(self, X, y):\n",
    "        \"\"\" Find split where children has lowest impurity possible\n",
    "        in condition where the purity should also be less than the parent,\n",
    "        if not, stop.\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        if n_samples <= 1:\n",
    "            return None, None\n",
    "\n",
    "        #so it will not have any warning about \"referenced before assignments\"\n",
    "        feature_ix, threshold = None, None\n",
    "\n",
    "        # Count of each class in the current node.\n",
    "        sample_per_class_parent = [np.sum(y == c) for c in range(self.n_classes)] #[2, 2]\n",
    "\n",
    "        # Gini of parent node.\n",
    "        best_gini = 1.0 - sum((n / n_samples) ** 2 for n in sample_per_class_parent)\n",
    "\n",
    "        # Loop through all features.\n",
    "        for feature in range(n_features):\n",
    "\n",
    "            # Sort data along selected feature.\n",
    "            sample_sorted = sorted(X[:, feature]) #[2, 3, 10, 19]\n",
    "            sort_idx = np.argsort(X[:, feature])\n",
    "            y_sorted = y[sort_idx] #[0, 0, 1, 1]\n",
    "\n",
    "            sample_per_class_left = [0] * self.n_classes   #[0, 0]\n",
    "\n",
    "            sample_per_class_right = sample_per_class_parent.copy() #[2, 2]\n",
    "\n",
    "            #loop through each threshold, 2.5, 6.5, 14.5\n",
    "            #1st iter: [-] [-++]\n",
    "            #2nd iter: [--] [++]\n",
    "            #3rd iter: [--+] [+]\n",
    "            for i in range(1, n_samples): #1 to 3 (excluding 4)\n",
    "                #the class of that sample\n",
    "                c = y_sorted[i - 1]  #[0]\n",
    "\n",
    "                #put the sample to the left\n",
    "                sample_per_class_left[c] += 1  #[1, 0]\n",
    "\n",
    "                #take the sample out from the right  [1, 2]\n",
    "                sample_per_class_right[c] -= 1\n",
    "\n",
    "                gini_left = 1.0 - sum(\n",
    "                    (sample_per_class_left[x] / i) ** 2 for x in range(self.n_classes)\n",
    "                )\n",
    "\n",
    "                #we divided by n_samples - i since we know that the left amount of samples\n",
    "                #since left side has already i samples\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (sample_per_class_right[x] / (n_samples - i)) ** 2 for x in range(self.n_classes)\n",
    "                )\n",
    "\n",
    "                #weighted gini\n",
    "                weighted_gini = ((i / n_samples) * gini_left) + ( (n_samples - i) /n_samples) * gini_right\n",
    "\n",
    "                # in case the value are the same, we do not split\n",
    "                # (both have to end up on the same side of a split).\n",
    "                if sample_sorted[i] == sample_sorted[i - 1]:\n",
    "                    continue\n",
    "\n",
    "                if weighted_gini < best_gini:\n",
    "                    best_gini = weighted_gini\n",
    "                    feature_ix = feature\n",
    "                    threshold = (sample_sorted[i] + sample_sorted[i - 1]) / 2  # midpoint\n",
    "\n",
    "        #return the feature number and threshold \n",
    "        #used to find best split\n",
    "        return feature_ix, threshold\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes = len(set(y))\n",
    "        self.tree = self._fit(X,y)\n",
    "        \n",
    "    def _fit(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes)]\n",
    "        #predicted class using the majority of sample class\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        \n",
    "        #define the parent node\n",
    "        node = Node(\n",
    "            gini = 1 - sum((np.sum(y == c) / n_samples) ** 2 for c in range(self.n_classes)),\n",
    "            predicted_class=predicted_class,\n",
    "            num_samples = y.size,\n",
    "            num_samples_per_class = num_samples_per_class,\n",
    "        )\n",
    "        \n",
    "        # task 1\n",
    "        if depth < self.max_depth:\n",
    "            #perform recursion\n",
    "            feature, threshold = self.find_split(X, y)\n",
    "            if feature is not None:\n",
    "                #take all the indices that is less than threshold\n",
    "                indices_left = X[:, feature] < threshold\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "\n",
    "                #tilde for negation\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "\n",
    "                #take note for later decision\n",
    "                node.feature_index = feature\n",
    "                node.threshold = threshold\n",
    "                node.left = self._fit(X_left, y_left, depth + 1)\n",
    "                node.right = self._fit(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        return [self._predict(x) for x in X_test]\n",
    "\n",
    "    def _predict(self, sample):\n",
    "        tree = self.tree\n",
    "        while tree.left:\n",
    "            if sample[tree.feature_index] < tree.threshold:\n",
    "                tree = tree.left\n",
    "            else:\n",
    "                tree = tree.right\n",
    "        return tree.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree feature ind:  0\n",
      "Tree threshold:  6.5\n",
      "Pred:  [0 0 1 1]\n",
      "ytest:  [0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "#fit starting with tree depth = 0\n",
    "Xtrain = np.array([[2, 5],[3, 5],[10, 5],[19, 5]])\n",
    "ytrain = np.array([0, 0, 1, 1])\n",
    "Xtest = np.array(([[4, 6],[6, 9],[9, 2],[12, 8]]))\n",
    "ytest = np.array([0, 0, 1, 1])\n",
    "\n",
    "model = DecisionTree(max_depth=10)\n",
    "model.fit(Xtrain, ytrain)\n",
    "pred = model.predict(Xtest)\n",
    "\n",
    "print(\"Tree feature ind: \", model.tree.feature_index)\n",
    "print(\"Tree threshold: \", model.tree.threshold)\n",
    "print(\"Pred: \", np.array(pred))\n",
    "print(\"ytest: \", ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree feature ind:  2\n",
      "Tree threshold:  2.45\n",
      "Pred:  [2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "dataset = load_iris()\n",
    "X, y = dataset.data, dataset.target\n",
    "\n",
    "model = DecisionTree(max_depth=10)\n",
    "model.fit(X, y)\n",
    "pred = model.predict([[2, 2.9, 6, 1.3]])\n",
    "\n",
    "print(\"Tree feature ind: \", model.tree.feature_index)\n",
    "print(\"Tree threshold: \", model.tree.threshold)\n",
    "print(\"Pred: \", np.array(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
