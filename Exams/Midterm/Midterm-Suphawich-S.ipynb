{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CP - Midterm - 2021\n",
    "## Instruction\n",
    "* Modify this file to be Midterm-<Your FirstName-[First Letter of Last Name]>, e.g., Midterm-Chaklam-S.ipynb\n",
    "* This exam is open-booked; open-internet.\n",
    "* You ARE NOT allowed to use sklearn or any libraries, unless stated.\n",
    "* The completed exams in **.ipynb AND .pdf format** shall be submitted at the Google Classroom \n",
    "* Any instructions not given, feel free to make any assumptions\n",
    "\n",
    "## Examination Rules:\n",
    "* Turn on your webcam during the entire period of the exam time\n",
    "* All work should belong to you. A student should NOT engage in the following activities which proctors reserve the right to interpret any of such act as academic dishonesty without questioning:\n",
    "* Chatting with any human beings physically or via online methods\n",
    "* Plagiarism of any sort, i.e., copying from friends. Both copee and copier shall be given a minimum penalty of zero mark for that particular question or the whole exam.\n",
    "* No make-up exams are allowed. Special considerations may be given upon a valid reason on unpredictable events such as accidents or serious sickness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (100 points): Basic Python Skills\n",
    "\n",
    "By now you should be comfortable with creating classes. Please complete the followings:\n",
    "\n",
    "1) First, please create a Candy() class \n",
    "- Please create a Candy() class that requires an input of 'color' attribute assigned in its <code> __ init __  </code>  function when you create an object.(4 point)\n",
    "- the second attribute in the <code> __ init __  </code> function is 'price' which should automatically be assigned according to colors:\n",
    "  * red costs 2 baht, blue costs 4 baht and others cost 6 baht (12 points)\n",
    "- Please add a <code> __ str __  </code> method that will allow you to print out the color and price of the candy (8 points)\n",
    "\n",
    "2) We will need another class called <code>CandyBasket()</code> which we will use to keep our candies in. This class should have the following methods (or functions) :\n",
    "\n",
    "- It should automatically create an empty basket when you create an object from this class.   \n",
    "  Please create 2 objects called <code>Basket1</code> and <code>Basket2</code> from the <code>CandyBasket()</code> class (8 points)\n",
    "  \n",
    "- Create a function for adding candy into the basket. <br>\n",
    "  Please add 3 Red candies and 3 Yellow candies into <code>Basket1</code>\n",
    "  and add 3 Blue candies into <code>Basket2</code>. (8 points)\n",
    "  \n",
    "- Create a <code> __ len __  </code> function that will allow you to print out the number of candies in the basket.  <br>\n",
    "  Please print out the number of candies in <code>Basket1</code> and <code>Basket2</code> (8 points)\n",
    "  \n",
    "- Create a <code> __ str __  </code> function that will allow you to print out the content of the basket.  <br>\n",
    "  Please print out the content of <code>Basket1</code> and <code>Basket2</code> (4 point)\n",
    "    \n",
    "- Also create a function that can plot a bar plot to show the number of candies of each color.  <br>\n",
    "  Please plot out the content of <code>Basket1</code> and <code>Basket2</code> (8 points)\n",
    "    \n",
    "    \n",
    "- Create a function for removing a candy from the basket you should be able to choose which candy to remove ! ) <br>\n",
    "  Please remove 2 Yellow candies from <code>Basket1</code> (12 points)\n",
    "  \n",
    "- Create a function that will allow you to transfer a specific color of candy from one basket to another. (It should also check and **raise and error** if you don't have the specific color of candy that you want to transfer)  <br>\n",
    "  Please transfer a Purple candy from <code>Basket2</code> to <code>Basket1</code> (it should give you an error).\n",
    "  and transfer 2 Red candies from <code>Basket1</code> to <code>Basket2</code>. (20 points)\n",
    "  \n",
    "- Create one last function that will calculate the total price of all candies in your basket. <br>\n",
    "  Please calculate and print out the total price of candies in <code>Basket1</code> and <code>Basket2</code> (8 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basket1 size: 6\n",
      "Basket2 size: 3\n",
      "Basket1 content:\n",
      "Color: red, price: 2\n",
      "Color: red, price: 2\n",
      "Color: red, price: 2\n",
      "Color: yellow, price: 6\n",
      "Color: yellow, price: 6\n",
      "Color: yellow, price: 6\n",
      "\n",
      "Basket2 content:\n",
      "Color: blue, price: 4\n",
      "Color: blue, price: 4\n",
      "Color: blue, price: 4\n",
      "\n",
      "After remove 'yellow'\n",
      "Basket1 size: 4\n",
      "Basket2 size: 3\n",
      "Basket1 content:\n",
      "Color: red, price: 2\n",
      "Color: red, price: 2\n",
      "Color: red, price: 2\n",
      "Color: yellow, price: 6\n",
      "\n",
      "Basket2 content:\n",
      "Color: blue, price: 4\n",
      "Color: blue, price: 4\n",
      "Color: blue, price: 4\n",
      "\n",
      "After transfer 'red' from basket2 to basket1.\n",
      "Basket1 size: 2\n",
      "Basket2 size: 5\n",
      "Basket1 content:\n",
      "Color: red, price: 2\n",
      "Color: yellow, price: 6\n",
      "\n",
      "Basket2 content:\n",
      "Color: blue, price: 4\n",
      "Color: blue, price: 4\n",
      "Color: blue, price: 4\n",
      "Color: red, price: 2\n",
      "Color: red, price: 2\n",
      "\n",
      "Total price of basket1:  8\n",
      "Total price of basket2:  16\n"
     ]
    }
   ],
   "source": [
    "class Candy:\n",
    "    def __init__(self, color):\n",
    "        self.color = color\n",
    "        if color == 'red':\n",
    "            self.price = 2\n",
    "        elif color == 'blue':\n",
    "            self.price = 4\n",
    "        else:\n",
    "            self.price = 6\n",
    "    def __str__(self):\n",
    "        return f\"Color: {self.color}, price: {self.price}\"\n",
    "    \n",
    "class CandyBasket:\n",
    "    def __init__(self):\n",
    "        self.basket = []\n",
    "\n",
    "    def add(self, candy):\n",
    "        self.basket.append(candy)\n",
    "    \n",
    "    def remove(self, color, max_color=1):\n",
    "        new_arr = []\n",
    "        for b in self.basket:\n",
    "            if b.color != color or max_color == 0:\n",
    "                new_arr.append(b)\n",
    "            else:\n",
    "                max_color -= 1\n",
    "        self.basket = new_arr\n",
    "\n",
    "    def tranfer(self, color, target, max_color=None):\n",
    "        objs = []\n",
    "        if max_color is None:\n",
    "            max_color = len(self.basket)\n",
    "        \n",
    "        for b in self.basket:\n",
    "            if len(objs) == max_color:\n",
    "                break\n",
    "            if b.color == color:\n",
    "                objs.append(b)\n",
    "                self.basket.remove(b)\n",
    "        if len(objs) == 0:\n",
    "            raise ValueError(f\"{color} does not exist.\")\n",
    "        for b in objs:\n",
    "            target.add(b)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.basket)\n",
    "    \n",
    "    def __str__(self):\n",
    "        s = \"\"\n",
    "        for b in self.basket:\n",
    "            s += f\"{b}\\n\"\n",
    "        return s\n",
    "    \n",
    "    def calculate(self):\n",
    "        total = 0\n",
    "        for b in self.basket:\n",
    "            total += b.price\n",
    "        return total\n",
    "    \n",
    "basket1 = CandyBasket()\n",
    "basket2 = CandyBasket()\n",
    "\n",
    "# add\n",
    "basket1.add(Candy('red'))\n",
    "basket1.add(Candy('red'))\n",
    "basket1.add(Candy('red'))\n",
    "basket1.add(Candy('yellow'))\n",
    "basket1.add(Candy('yellow'))\n",
    "basket1.add(Candy('yellow'))\n",
    "basket2.add(Candy('blue'))\n",
    "basket2.add(Candy('blue'))\n",
    "basket2.add(Candy('blue'))\n",
    "\n",
    "# print out\n",
    "print(\"Basket1 size:\", len(basket1))\n",
    "print(\"Basket2 size:\", len(basket2))\n",
    "\n",
    "\n",
    "print(f\"Basket1 content:\")\n",
    "print(basket1)\n",
    "print(f\"Basket2 content:\")\n",
    "print(basket2)\n",
    "\n",
    "# remove yellow\n",
    "basket1.remove('yellow', max_color=2)\n",
    "print(f\"After remove 'yellow'\")\n",
    "print(\"Basket1 size:\", len(basket1))\n",
    "print(\"Basket2 size:\", len(basket2))\n",
    "print(f\"Basket1 content:\")\n",
    "print(basket1)\n",
    "print(f\"Basket2 content:\")\n",
    "print(basket2)\n",
    "\n",
    "# test transfer\n",
    "basket1.tranfer('red', basket2, max_color=2)\n",
    "print(f\"After transfer 'red' from basket2 to basket1.\")\n",
    "print(\"Basket1 size:\", len(basket1))\n",
    "print(\"Basket2 size:\", len(basket2))\n",
    "print(f\"Basket1 content:\")\n",
    "print(basket1)\n",
    "print(f\"Basket2 content:\")\n",
    "print(basket2)\n",
    "\n",
    "# price\n",
    "print(f\"Total price of basket1: \", basket1.calculate())\n",
    "print(f\"Total price of basket2: \", basket2.calculate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (195 points): Data Science\n",
    "\n",
    "Complete the following data science pipeline:\n",
    "\n",
    "1) **Loading**:  Load boston data from sklearn.datasets (5 points) <br>\n",
    "\n",
    "2) **Feature Selection/Engineering**\n",
    "\n",
    "* Perform some basic exploratory data analysis as appropriate to determine what are the top five features potentially useful for the prediction (15 points) <br>\n",
    "\n",
    "* Create X using the top five features, and the corresponding y (10 points) <br>  \n",
    "\n",
    "* Do train test split the data **FROM SCRATCH** (5 points) <br>\n",
    "\n",
    "* Scale your data **FROM SCRATCH** using **Box-Cox transform** with $\\lambda$ = -1 (15 points) : (6.3.2.2. Mapping to a Gaussian distribution **Box-Cox transform**) https://scikit-learn.org/stable/modules/preprocessing.html#mapping-to-a-gaussian-distribution <br>\n",
    "\n",
    "$$\n",
    "x_i^{(\\lambda)} = \\begin{cases}\n",
    "      \\displaystyle\\frac{x_i^{(\\lambda)} - 1}{\\lambda} & \\text{if }  \\lambda \\neq 0  \\\\\n",
    "      \\ln (x_i) & \\text{if } \\lambda = 0 \\\\\n",
    "      \\end{cases}\n",
    "$$\n",
    "\n",
    "3) **Model Implementation**: Implement Linear Regression class **FROM SCRATCH** with the following features <br>\n",
    "* choice of **weight initialization** (normal distribution with mean=0 and std=1, random between 0-1, all zero) (15 points)\n",
    "* choice of **sampling method** (batch, mini batch, stochastic) (15 points) \n",
    "* **raise ValueError** where appropriate (5 points) \n",
    "* use **without replacement** for stochastic  (5 points) \n",
    "* choice of **loss function** (normal, ridge)   (15 points) \n",
    "    * normal loss function\n",
    "    \n",
    "        $$J(\\theta) = \\frac{1}{2}\\sum_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})^2$$    \n",
    "    \n",
    "        $$\\frac{\\partial J}{\\partial \\theta_j} = \\sum_{i=1}^{m}(h^{(i)}-y^{(i)})x_j$$\n",
    "\n",
    "    * ridge loss function\n",
    "    \n",
    "        $$ J(\\theta) = \\frac{1}{2}\\sum_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})^2 + \\lambda\\sum_{i=1}^n \\theta_i^2$$\n",
    "        \n",
    "        $$\\frac{\\partial J}{\\partial \\theta_j} = \\sum_{i=1}^{m}(h^{(i)}-y^{(i)})x_j + \\lambda \\theta_j$$\n",
    "\n",
    "* Implement a feature importance function **FROM SCRATCH** which will output a bar plot, plotting the importance scores of each features in sorted order (15 points).\n",
    "    * If we have scaled our data in our beginning (e.g., standard scaler), feature importance scores are simply the weights.  Larger weights imply stronger importance.  Anyhow, plotting them can be nasty since some weights can be very big, thus you may want to log-transform them. \n",
    "\n",
    "4) **Training/Experiment**: Implement a cross validation experiment **FROM SCRATCH** comparing their cross-validation accuracy, and output their feature importance scores (15 points)\n",
    "\n",
    "* mini-batch sampling, normal loss\n",
    "* mini-batch sampling, ridge loss with lambda of 0.05\n",
    "* stochastic sampling, normal loss\n",
    "* stochastic sampling, ridge loss with lambda of 0.05\n",
    "\n",
    "5) **Training/Testing**: Select the best parameters you found in 4), train and verify the best model with the testing set. Plot training and testing losses and accuracies as number of iters increases (10 points)\n",
    "    \n",
    "6) **Communication**: Interpret your results (e.g., overfitting, weights, accuracy, etc.).  Critical analyses will be used as main criteria for scoring (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection/Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = boston.feature_names\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, percent_train=.7):\n",
    "    idx = np.arange(0,len(X),1)\n",
    "    np.random.shuffle(idx)\n",
    "    idx_train = idx[0:int(percent_train*len(X))]\n",
    "    idx_test = idx[len(idx_train):len(idx)]\n",
    "    X_train = X[idx_train]\n",
    "    X_test = X[idx_test]\n",
    "    y_train = y[idx_train]\n",
    "    y_test = y[idx_test]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def boxcox(X, lam=0):\n",
    "    if (lam==0):\n",
    "        return np.log(X)\n",
    "    top = (X ** lam) - 1\n",
    "    return top / lam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to choose last 5 features of the dataset to be top feature for training this model because it can be impact directly to the house prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- DIS      weighted distances to five Boston employment centres\n",
    "- RAD      index of accessibility to radial highways\n",
    "- TAX      full-value property-tax rate per $10,000\n",
    "- B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- LSTAT    % lower status of the population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston.data[:, [7, 8, 9, 11, 12]]\n",
    "y = boston.target\n",
    "X = boxcox(X, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (354, 6)\n",
      "X_test: (152, 6)\n",
      "y_train: (354,)\n",
      "y_test: (152,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, percent_train = 0.7)\n",
    "\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "assert X_test.shape[0] == y_test.shape[0]\n",
    "\n",
    "# add intercept to our X\n",
    "intercept = np.ones((X_train.shape[0], 1))\n",
    "X_train   = np.concatenate((intercept, X_train), axis=1)  #add intercept\n",
    "intercept = np.ones((X_test.shape[0], 1))\n",
    "X_test    = np.concatenate((intercept, X_test), axis=1)  #add intercept\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "print(\"y_train:\", y_train.shape)\n",
    "print(\"y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, alpha=0.001, max_iter=10000,\n",
    "                 weight_method=\"zero\", fit_method=\"batch\", loss_method=\"normal\",\n",
    "                 without_replacement=True, ridge_lamda=0.05):\n",
    "        self.alpha = alpha\n",
    "        self.max_iter = max_iter\n",
    "        self.losses = []\n",
    "        self.weight_method = weight_method # normal, random, zero\n",
    "        self.fit_method = fit_method # batch, sto, minibatch\n",
    "        self.loss_method = loss_method # normal, ridge\n",
    "        self.ridge_lamda = ridge_lamda\n",
    "        self.without_replacement = without_replacement\n",
    "    \n",
    "    def init_weight(self, n):\n",
    "        method = self.weight_method\n",
    "        if method == \"normal\":\n",
    "            self.theta = np.zeros(n)\n",
    "        elif method == \"random\":\n",
    "            self.theta = np.random.rand(n,)\n",
    "        elif method == 'zero':\n",
    "            self.theta = np.zeros(n)\n",
    "        else:\n",
    "            raise ValueError(f\"Weight method is invalid.\")\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        self.init_weight(X.shape[1])\n",
    "        iter_stop = 0\n",
    "        list_of_used_ix = [] #<===without replacement\n",
    "        \n",
    "        for i in range(self.max_iter):\n",
    "            if self.fit_method == \"sto\":\n",
    "                i = np.random.randint(X.shape[0])\n",
    "                if self.without_replacement:\n",
    "                    while i in list_of_used_ix:\n",
    "                        i = np.random.randint(X.shape[0])\n",
    "                X_train = X[i, :].reshape(1, -1)\n",
    "                y_train = y[i]\n",
    "                list_of_used_ix.append(i)\n",
    "                if len(list_of_used_ix) == X.shape[0]:\n",
    "                    list_of_used_ix = []\n",
    "            elif self.fit_method == 'minibatch':\n",
    "                batch_size = int(0.3 * X.shape[0])\n",
    "                ix = np.random.randint(0, X.shape[0]) #<----with replacement\n",
    "                X_train = X[ix:ix+batch_size]\n",
    "                y_train = y[ix:ix+batch_size]\n",
    "            elif self.fit_method == 'batch':\n",
    "                X_train = X\n",
    "                y_train = y\n",
    "            else:\n",
    "                raise ValueError(f\"Fit method is incalid.\")\n",
    "\n",
    "            loss, grad = self.gradient(X_train, y_train)\n",
    "            \n",
    "            # update theta\n",
    "            self.theta = self.theta - self.alpha * grad\n",
    "            self.losses.append(loss)\n",
    "\n",
    "    def predict(self, X): # <--- X_test\n",
    "        return self.h_theta(X)\n",
    "\n",
    "    # can name it predict for easy understanding\n",
    "    def h_theta(self, X):\n",
    "        return X @ self.theta\n",
    "\n",
    "    def mse(self, yhat, y):\n",
    "        return ((yhat - y)**2 / yhat.shape[0]).sum()\n",
    "\n",
    "    def normal_loss(self, yhat, y, X):\n",
    "        return np.dot((yhat - y), X).sum()\n",
    "    \n",
    "    def ridge_loss(self, yhat, y, X):\n",
    "        return self.normal_loss(yhat, y, X) + np.dot(self.ridge_lamda, self.theta).sum()\n",
    "\n",
    "    def gradient(self, X, y):\n",
    "        yhat = self.h_theta(X)\n",
    "        if self.loss_method == 'normal':\n",
    "            loss = self.normal_loss(yhat, y, X)\n",
    "        elif self.loss_method == 'ridge':\n",
    "            loss = self.ridge_loss(yhat, y, X)\n",
    "        else:\n",
    "            raise ValueError(f\"Loss method is invalid.\")\n",
    "        grad = X.T @ (yhat - y)\n",
    "        return loss, grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X_train, X_test, y_train, y_test, arr_params):\n",
    "    for i, params in enumerate(arr_params):\n",
    "        model = LinearRegression(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "        mse = model.mse(yhat, y_test)\n",
    "        print(f\"Cross: {i+1}, MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross: 1, MSE: 21.726659566173538\n",
      "Cross: 2, MSE: 21.788568599813225\n",
      "Cross: 3, MSE: 77.60200825282163\n",
      "Cross: 4, MSE: 76.74363584346028\n"
     ]
    }
   ],
   "source": [
    "arr_params = [\n",
    "    {'fit_method': 'minibatch', 'loss_method': 'normal'},\n",
    "    {'fit_method': 'minibatch', 'loss_method': 'ridge', 'ridge_lamda': 0.05},\n",
    "    {'fit_method': 'sto', 'loss_method': 'normal'},\n",
    "    {'fit_method': 'sto', 'loss_method': 'ridge', 'ridge_lamda': 0.05},\n",
    "]\n",
    "\n",
    "cross_validation(X_train, X_test, y_train, y_test, arr_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training/Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 21.739822258867786\n",
      "Theta: [ 49.21443085  -1.55767283  -1.10069228  47.44446912   2.30196113\n",
      " -83.8856549 ]\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression(**arr_params[0])\n",
    "model.fit(X_train, y_train)\n",
    "yhat = model.predict(X_test)\n",
    "mse = model.mse(yhat, y_test)\n",
    "\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"Theta: {model.theta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAyCklEQVR4nO3deXhU1f3H8feXEBL2fQ1gQDYB2Yws7gICihVFUFxRbGmtVrFVC+KKUrFaF1qX+qugVSuouFARUVDcikBQVgEJixD2NSwSyHJ+f9ybMEkmIcDcJCSf1/PMk5lz7rlzzmRmvvece+Yec84hIiISpHLFXQERESn9FGxERCRwCjYiIhI4BRsREQmcgo2IiAROwUZERAKnYCMiIoFTsBEJmJmtM7PexV0PkeKkYCMiIoFTsBEpBmYWY2bPmtkm//asmcX4eXXM7CMz22Nmu8zsazMr5+f92cw2mtk+M1tpZr389HJmNtLMVpvZTjN728xq+XmxZvaGn77HzOabWf3ia72URQo2IsVjNNAd6AR0BLoC9/t5fwKSgbpAfeA+wJlZa+B24EznXFWgL7DOL3MHcDlwPtAI2A087+cNBaoDTYDawO+Ag0E1TCQcBRuR4nEdMMY5t805tx14BLjBz0sDGgKnOOfSnHNfO+8ihhlADNDWzKKdc+ucc6v9Mr8FRjvnkp1zh4CHgUFmVt7fX22ghXMuwzm3wDm3t8haKoKCjUhxaQT8HPL4Zz8N4EkgCfjUzNaY2UgA51wSMAIvkGwzs0lmllXmFOB9f5hsD7AcLzjVB14HZgCT/CG7v5pZdJCNE8lNwUakeGzCCxBZmvppOOf2Oef+5JxrDvwK+GPWuRnn3H+cc+f4ZR3whF9+A3Cxc65GyC3WObfR7x094pxrC5wFXArcWCStFPEp2IgUjWj/RH2smcUCbwH3m1ldM6sDPAi8AWBml5pZCzMzYC9eDyXDzFqbWU9/IkEq3nmXDH//LwFjzewUfx91zWyAf/9CMzvdzKL8/aWFlBMpEgo2IkXjY7zgkHWLBRKBxcAS4HvgMX/blsBMYD8wB3jBOTcb73zNOGAHsAWohzd5AOA5YCre0Ns+4Dugm5/XAHgXL9AsB77ED2wiRcW0eJqIiARNPRsREQmcgo2IiAROwUZERAKnYCMiIoErX9wVKGnq1Knj4uPji7saIiInlQULFuxwztXNL1/BJpf4+HgSExOLuxoiIicVM/u5oHwNo4mISOAUbEREJHAKNiIiEjgFGxERCZyCjYiIBE7BRkREAqdgIyIigVOwiaBlm1L4Yf3usHmZmY5t+1KLuEYiIiWDgk0E9R//DVe88L8caYnrdvHJ0i28+OVquo6dxYZdvxRT7USkqKzYslcHl7ko2ASg51Oz+WbVDm54ZS6DXprD795YwOyV2wDYnOK9ASd8s5aHPlyap+zWvanc8dYP7DpwOEf67gOHSdq2L/jKi5RC7yRuIH7ktCILAP2e/Zrz/vpFkTzXyULBJgBrdhzg+lfm8vWqHdlp6ZlHFqmLHzmNMR/9yGtz8l7dodtfZjF10SbunPRDjvR+z31F76e/Cq7S+fhw4Ua27o3sB9Q5R2pa4VYlPpSeQUbm0Rf4ix85jT+89cNRtzuatIxMDqdn5klP2raPv3y8nPSMvHmRtCUllTH//TG7zRmZjv2H0k94v5kR2s/J6u3EDQCs3X4gT156RiYHcr02M5ZtYdK89fnub8ayLazfWfAoRWpa5N4r89buIi3g917QFGyKyA/r9wAwdMK8HOkHDqXz/frd/C9pB/Ejp2Wnf73Ke/zzzgPs3H+IrXsPZeelZ2QyftYqVm/fz+6QHtD0JZuZs3on89ftYtbyrWHrkbz7Fw6lZ7BtXyqbUw4yZ/VORk5ZzPx1u9iSkjOoHDiUzp2TFnL9v+YetX2PT1/Oi7NXH3U7gBdmr6bNA5/w3vfJ+W6T8ksa6RmZtL7/E4a9Oh+AbXtTs4NUysG0PB/2/y7aRN9nvuKmiUde4617U1m5pfA9wp5/m02r+6cTuoJtZqaj99Nf8fJXa3hu1qpC7yur7LZjCNb3TlnMhG/X8t2anQA88t9ltH9oRtgAWFifr9hK8/s+pv1DM9jzy+Gw2+z55TA79x8Kmxdq4rdr+TZpx1G3OxE79x/igx82smxTygnva9byrXz241YMy5F++3++J37kNFrfP50Wo6fT7qEZOfJ/+/oCRr63JM/+MjMdh9Mz+e3rC+j77LEd/O06cJg35+Y9wIwfOY2Hpy7Lt9zSjSlc9c85jJu+osD97z+Uzq/+/g1dx84scLu7Ji+k199mF6rOkaQLcRaxg7mO6O+avJBPfwwfGADOf3J2nrT3ftjI05/9xNOf/QTAPX1bM7BLHLe++X2O7daN68/r3/3Mis17GXvF6RxOz+ScJ77gktMb8PGSLTm2nTR/Q3aZLBn+F+6qbfu5aeI8nrmqEzUrV8hTn6Rt+/nnl2sArye0LzWdb0f2zLHNfe8v4T9z17PwwYv44IeNAPzx7UUM7NKYfalpxEZHcTg9k8ox5cnIdHQc8ymDz2gMwJc/bQeg619m0bVZLe7u05qr/jknT30BVm7dx8qtR4JLt7/MCrvd2h0H2HswjY5NagBwOD2T79fvZsOugwA8/0USt/dsCUBov+rvnydxY4946laNyfM6hDP+81U8O3MV/xvZk0Y1KmanO+d4ZuYqDqVlcEHrevQ4tTYAGZmZfr633ZQFXkBOTc+gQnnv2HDbvlTKmTHk5e9I2rYfgHEDT+fSjo2oEpP3Iz3s1SMXlp23dheJP+9m6FnxxIXUp9OYzwCIKV+OQ+mZPHHl6Vx9ZtM8+3rkvz8C8MXdF1C5QhR/emcRSdv2M2dUL1LTMnj+iyRuu7AFsdFRYV+PzSkHaVj9yPP+cjid8uXKsW1fKk/OWMmHCzfl2P66bk15/4eNvPWb7nRsUoO0jEzW7ThAy/pVw+4fvIOxzSmpNKlViVtey3lR3U0pB0lNy+CjxZsBOHSUIP7T1n208p/rUHoGre//JDsv92cZYOWWffkGoS6Peq9x24bV6Ny0Zo68V/+3jtH9TyM66sjx/7jpKyhn0K2599545Zu1fLhwI+0aVee1YV2zt9uSksryLXu5eeL87LTUtAzW7jjA9n2HOK9VXdbv/IXrXvmOd357Fu/7n7/J89eH/R8HRcGmmBUUaMKJHzmNHv6bL8uTM1by5IyVebZ99du1POx/OfRr3yD7iyt3oMm9/1b1q/DT1v10bVYrO332yu10fvQzPvrDOWRkOl7/7mfeXZDMDd1PyXGku8LvRaSmZRAbHcU1L39HemYm89d5s/Q6jfmMBtVis7f/fv1uBoZMqvjroA7ZXwDv+R8KIDuwzlu7KzvQZNV3yq09wrYldBikzzNfsm7nL7xwbRdOa1SNC5+aDRwJQmOn5RzWnLpoE7f3bMne1DQq5frifOWbtfRsU49lm1LYl5rOmfG1uOb/vgNg1p/O56NFm7mwTV1qVKzAszO9ntDmlIP839draF6nMg98uIwJNyUw3u8l/fOrNcwb3Yv1O3/h2ySvR+PIOXTY4eFP+fKeC7jtP9+zdOPePG0d+d4SRr63hHXj+nMoPYMDhzLo8uhndGhcPcd2w19fkP3aLH64b579ZL32f56yhD9PWcL/3ZjARW3r59nuixXbmPi/tdnBObRXXrFCFL+/oEXeMiu3cfPE+TSsHkunJjXYlJLKog178mwX6s253v9wwPPf8sYt3bj+Fa+X/Z/fdOPF2av5etUO5t3Xi3r+eyotI5OWo6cDMO2Oc/Ls767Ji7hr8qKwz3Xli//jz/3aUDX2yNfipeO/4aexF2cfLOUnvyCT9bqEHuzs9nuXmZmOV75Zm50+fekWLj29If/6Zg1/+fhIL6ZWyAHejv2Hsw++AOas3snv3lhAysG0HM978XNfs3aHN2R4Y49T+Lf/3u7++KzsbZ6c8RPf/7yHyYkb8hyMBcFChwsEEhIS3PEuMRD6gStpsgJIUbmmaxPu7duGzv7RXFH7+zWd8z2H07ddfWYs84L8unH9OevxWWxKyTvUNfGmM7n51fm8NqxrnuHPY1W+nOU4b3c0/7i2M5d2aJTjPRVXoyIb9xwssNw1XZvy1rz1nNuyTo5zhuG0a1SNv13VkadmrGTm8m35bteyXhVWbdvPqIvb8PhRhnIAzm1Zh4rRUazZcYA/9GxB8zpVeG7WKmbmM7R7PMYMaMeDHx4Zehp8RmPuv7QtHR/5NDutSkz5iJynWvOXS2h+38dh8+7o2YLxnycddR+PXd6e+z/wJgT9+pxm3H9pWz5espnf5xqNKKx14/rz6Ec/5ghWJ+KBS9vy6Ec/cmOPUxgzoP1x7cPMFjjnEvLNV7DJqbQGm6LWpWkNYqOj+N/qncVdlQIteqhPji+ocOpUqcCO/eHPdQSpsF/u4mlepzJrduSdAHCifnNuM/7v68h8qWdZN64/zUdN4xiOP3K4tlvTAntaJ+J4ezkKNsdIwUZEgpbVWyyJggo2mo0mIlLESmqgCZKCjYiIBK5MBBsz62dmK80sycxGFnd9RETKmlIfbMwsCngeuBhoC1xjZm2Lt1YiImVLqQ82QFcgyTm3xjl3GJgEDCjmOomIlCllIdjEARtCHif7aSIiUkTKQrCxMGk55nub2XAzSzSzxO3bt4fZXERETkRZCDbJQJOQx42BHBdgcs697JxLcM4l1K1bt0grJyJSFpSFYDMfaGlmzcysAjAEmFrMdRIRKVNK/YU4nXPpZnY7MAOIAiY45/K/nreIiERcqQ82AM65j4HwV9ITEZHAlYVhNBERKWYKNiJl3OWdGhV3FUqFM06pefSNyjAFGymRYsqX463fdM83P9yVaW8+Ox7w1mm5v/9p2ekXtq7Lmr9cEpF6vXFLtwLz54w6skLpOS3qhN2mW8iidMXtis5xPDukMwA1KkUz5daz+G5UL9o1qpZju6sTmoQrfsKeGtzxhMqHvg+evboTAF3ja3FN16JbgTJLuXA/sigC7/wu/OKB4C1TEc6YAe145LJ2rHi0H3Wq5F19NwgKNqVQ+7hqtGmQ/7K5AK0LWFY3P52b1jiu+lzWMfyR8+8vOJVhZzfLkXZ996YsuL83Kx+7mB6n1iZp7MU58h+5rB3zR/fOs6/mdSozoncralSK5qFfteOWc47sd8JNZ1KunLFuXH/Ob3VkavvMP57PIH/p6cJoVD2Wc1rWYcnDfZg0PG8grF8tJseSx88O6RR2P3Wq5L+k9CcjzmXpI325u08rAK5KyFu/Eb1b5ls+XC9lyJlNeODSttzY45TstCu7NOanxy7mGf8L+qfHLmb+6N6ccUpNGlSPZdod5/LDAxdlb//o5e2Zfue5ADw5qAO/OTfn/y30/zi0xyksfrgPAGaQ4B/xly9n1K8Wwx8vapW97aAzGrPooT789vzmrBp7Me///qzsvNr+CpUf3HY2ix/uw5f3XMC6cf1ZN64/TWodeZ1/e35znhvSics7x/H1vRfy9u968PjA0/N9jZ6/tkt2/S9qW58pt/ZgYOej/84762Amt0/vOg+Ai9s35MPbzs5u69Hk/ozOva9Xjse/v+BUep9WL/vxxJvODLufM+NrMeGmBLo1q5VnOfbLOjVi3bj+fHrXeXxw29k8dnl7Zow4jxt7xDP0rPg8y3eHfm4irUxMEDhZ/LlfG9747uejrsZYkMcHns7F7RuwdOPe7CV0c/tkxLm0aVAte/2dC1vX5YuVOX/M+qeLWjGgUxznPfkFt15wKi/OXg3A3X1a8dSnP9GtWS3+fk1n9h9K59mZq7jrolbZSy1neW1YV26eOI/h5zVn7BXtWbFlH4Nf8pZ0vuWcZtzTtzVmxoO/aktmprcQclSuD2nux5d3iqN6pWjACxa9n/6SGSPOo7X/wV34YJ/sbVc82o+ocobZkX28Nqwr46av4KUvVxNXoyKPDzyddxckUyWmPKfWq8KiDXto06AqnZrUYNL8DfQ+rX72CpOjLvF6S1Vjo+nevDaTh3fn61U7+McX3kqNtSrnDCJ1qsTw5q+7cd2/vP9D0tiLyXQw8r3FObZ7/tou3PYfb8XGNg28HsVVCU34aPFmRvRuxZ/7tWHA89+SvNt7X9x2YQtuv7AF905ZzHvfH1k6e8JNCSzfvC/HvpvWqsRjl7enfFQ50jMyubNXS2qHCXYVyuc97qxZuQJtG1bjx817qVC+HKc1rJajJ/Hnfm24+51F3Hx2Mzo2qcG5repw88T5DOgcR7XYaBLv702NitGUM6P5fR9z89nxjO7vXZbw6c9+ontzr4dXvWI0oy72XtvOTY8MRU2741xWbNlLpyY1AKgWG52dN/OP55PprWCdXRagSa1KedqR5aqExoy94nSio8rRv0ND+ndoRJsGVYmNjqJ9XHXe+2Ej9avFMPc+72Am6/OReH9vfty0l3Na1OG3552aY2nlWy84lVb1q7Lskb5UqhCFmTHhpgS6N69N2wdnZG+3blx/1u/8hQ8XbmTaks2s2LKPRy9vz+CX5tCyXhVOa1iN+v7S1p2b1uD5a7vQqIYXUNfuOEDV2PJUruB9Xf9tcEcuOb0hpz34Sfb+e7apT8823vLdj1zWjoemLuPKLo2zl2Bv5R9cZr2WoZrUqsSO/Yf5x7Wd6dO2Qb6v34nS4mm5FOfiaevG9WfjnoOcPe7zPHn39z+Nx6Ytp0fz2rw1vDurtu5j2pLN2Wvc57fgUVadnhvSiTsnLeTzP51P87pVcuStG9efi57+klXb9jNjxHlUiS1PXI0jR44ZmY6Hpi5l+Lmnsjc1jUv//g1XJzThiUEdwj7X4DMa07FJDa7vfgq5xY+cxrkt6/D6UYajQi3dmMJHizdzQeu6dG9eu9Dl8pOZ6TickZl9VPfJ0i10aVqDl79aw7++Wct9l7ShS9OaDHppDrP+dD67Dxxmzy9p9DqtXo7AleU/c9dz3/tLOK1hNabfeS6b9hxk5/7DnN64enab4cj/6JOlW/jdGwuyy68b15/r/zWXb5J25Pt/TMvIpOXo6Tn2A+CcY/L8DWzac5C7LmpF4s+7GfzSHJ65uiOLk1MYfclplI86/gGMlF/SWLfzAB3DfEmFk5qWkedoOaueQPbrl+kvUVkuTA8g9+t1vEa/v4RyZvRuW58zTqlJlZiCj62Ttu2nduUK1PR7VOHqsSUlNTvYnNOiDq/f0jXsewK8z82p/nLSofs4nJ5JRqajYoW8r9PmlIPUrFQh7GuYW36vk3OOPb+kZbfjaHYdOMy8tbvo1/7EAs3RFk9Tz6YYdWtWi6cGd+TbpB0kxHtHdHE1KlK/Wgxb9x7iis5xvP+Dd+Tat533RrjMHyZpWb8qI+pXpW+7BmQW4oBhQKc4BnTKOVQwb3Qv0jK8si9e34V/fb2WFvWqhO1dPHb5kWGJCTclcNapec9HvPu7Hhw4nJFjqCq3tY9fku+HMz/t46rTPq76MZUpSLlyRmy5Ix/mrA/ZDT1OYfrSLVzWMY4G1WOPfIiPclGJs1t4AbBZHe+oulGNitlHpVlOqX3kiLtf+wbMvvsCPly4iTt6tQC8ob6DaRn519l/zXKfBzIzhoScnzgzvhYrH+tHTPkoruhc+CHC/FSvFE3HSjUKvX1+X5K5/+fhgkyWcQNPp+VxDPPmNvaK/IfSwmlRr8pRt6ka631l/vb85jl6VOHk/hxlCdeLzBI6DHu8zKzQgQagVuUKJxxoCkM9m1yC7NkMO7sZE749spZ5t2a1mPzbvCf31u/8hW+SdjCwSxxtHvC6yt+O7Jmjt1FYX6zYRrlyVmAAkBP3xcptdI2vReUwR8+H0zMxg+gT6GEA/LR1H3E1KoZ9Dom8uWt2UrNyhewhqCwHDqVTMTqqwICZZdrizVSKieLC1vWOuu2xilQPMFLUsylmU28/mze/W0+D6rH0bFMvR7C5Kp8ZPk1rV+La2t7R6lf3XMgHCzfSqHrscT3/hW0i/yaXvAr6MinoSPZY5P7Sk2B1y2fI9liCff8ODSNVnTz+NrgjDY7ze6E4KNgEIOskOkCHxjXoMKgG4I1/g3f+JPeQVn6a1q7EHb3yn30kImXTlccwk7IkULCJsGZ1KnN7T2/GT91cs36qV4ouMV1eEZGipGATQdFRxsX+ibbi+FGZiEhJpR91iohI4BRsREQkcAo2EaRZ5CIi4SnYRNgx/l5RRKRMULAREZHAKdiIiEjgFGxERCRwCjYiIhI4BZsI0mQ0EZHwSlywMbMnzWyFmS02s/fNrEZI3igzSzKzlWbWNyT9DDNb4ueNN/965mYWY2aT/fS5ZhYfeP3RdDQRkdxKXLABPgPaO+c6AD8BowDMrC0wBGgH9ANeMLOsxTNeBIYDLf1bPz/9FmC3c64F8AzwRFE1QkREjihxwcY596lzLt1/+B2QdWnTAcAk59wh59xaIAnoamYNgWrOuTnOW5zn38DlIWVe8++/C/SyY125S0RETliJCza5DAOm+/fjgA0hecl+Wpx/P3d6jjJ+AEsB8ixSYWbDzSzRzBK3b98e0QaIiEgxXfXZzGYC4dYhHe2c+9DfZjSQDryZVSzM9q6A9ILK5Exw7mXgZfBW6iyw8iIicsyKJdg453oXlG9mQ4FLgV7uyLrVyUDo0paNgU1+euMw6aFlks2sPFAd2HXCDciHltgWEQmvxA2jmVk/4M/AZc65X0KypgJD/BlmzfAmAsxzzm0G9plZd/98zI3AhyFlhvr3BwGfu4Ajgs4IiYjkVRIXT/sHEAN85p/L/8459zvn3DIzexv4EW947TbnXIZf5lbgVaAi3jmerPM8rwCvm1kSXo9mSJG1QkREspW4YONPU84vbywwNkx6ItA+THoqMDiiFRQRkWNW4obRRESk9FGwERGRwCnYiIhI4BRsIkgTn0VEwlOwiTDNfBYRyUvBRkREAqdgIyIigVOwERGRwCnYiIhI4BRsIkjX4RQRCU/BJtJ0JU4RkTwUbEREJHAKNiIiEjgFGxERCZyCjYiIBE7BRkREAqdgE2GaiyYikpeCjYiIBE7BRkREAqdgIyIigVOwERGRwJXYYGNmd5uZM7M6IWmjzCzJzFaaWd+Q9DPMbImfN97Mu2aMmcWY2WQ/fa6ZxQdVX6cLo4mI5KtEBhszawJcBKwPSWsLDAHaAf2AF8wsys9+ERgOtPRv/fz0W4DdzrkWwDPAE8HXPehnEBE5+ZTIYIMXGO4FQrsLA4BJzrlDzrm1QBLQ1cwaAtWcc3Oc1734N3B5SJnX/PvvAr2yej0iIlJ0SlywMbPLgI3OuUW5suKADSGPk/20OP9+7vQcZZxz6UAKUDvMcw43s0QzS9y+fXtE2iEiIkeUL44nNbOZQIMwWaOB+4A+4YqFSXMFpBdUJmeCcy8DLwMkJCTo5IuISIQVS7BxzvUOl25mpwPNgEX+aFdj4Hsz64rXY2kSsnljYJOf3jhMOiFlks2sPFAd2BW5loiISGGUqGE059wS51w951y8cy4eL1h0cc5tAaYCQ/wZZs3wJgLMc85tBvaZWXf/fMyNwIf+LqcCQ/37g4DPXUDTxjQZTUQkf8XSszkezrllZvY28COQDtzmnMvws28FXgUqAtP9G8ArwOtmloTXoxkSdD1NV0cTEcmjRAcbv3cT+ngsMDbMdolA+zDpqcDgoOonIiKFU6KG0UREpHRSsBERkcAp2IiISOAUbCJEk9FERPKnYBNhuhiOiEheCjYiIhK4Yw42ZlbTzDoEURkRESmdChVszGy2mVUzs1rAImCimT0dbNVERKS0KGzPprpzbi8wEJjonDsDCHt9MxERkdwKG2zK++vGXAV8FGB9TlpaqVNEJH+FDTZjgBnAaufcfDNrDqwKrlonL01GExHJq1DXRnPOvQO8E/J4DXBlUJUSEZHSpbATBFqZ2SwzW+o/7mBm9wdbNRERKS0KO4z2f8AoIA3AObeYIrhcv4iIlA6FDTaVnHPzcqWlR7oyIiJSOhU22Owws1PxLwFmZoOAzYHV6iSkuWgiIvkr7OJptwEvA23MbCOwFrg+sFqdxHRtNBGRvAo7G20N0NvMKgPlnHP7gq2WiIiUJoWdjXanmVUDfgGeMbPvzaxPsFUTEZHSorDnbIb5l6vpA9QDbgbGBVYrEREpVQobbLLORFyCd220RejH8iIiUkiFDTYLzOxTvGAzw8yqAplBVcrM/mBmK81smZn9NSR9lJkl+Xl9Q9LPMLMlft54M+80vZnFmNlkP32umcUHVWddGk1EJH+FnY12C9AJWOOc+8VfauDmICpkZhcCA4AOzrlDZlbPT2+L90PSdkAjYKaZtXLOZQAvAsOB74CPgX7AdL/eu51zLcxsCPAEcHUQ9Q6pf5C7FxE5KRW2Z9MDWOmc22Nm1wP3AykB1elWYJxz7hCAc26bnz4AmOScO+ScWwskAV39q1FXc87Ncd6ll/8NXB5S5jX//rtAL1M0EBEpcoUNNi8Cv5hZR+Be4Ge8L/UgtALO9Ye9vjSzM/30OGBDyHbJflqcfz93eo4yzrl0vABZO/cTmtlwM0s0s8Tt27dHtDEiIlL4YbR055wzswHAc865V8xs6PE+qZnNBBqEyRrt16km0B04E3jbX9IgXI/EFZDOUfKOJDj3Mt6PVklISNDZFxGRCCtssNlnZqOAG/B6HVFA9PE+qXMu31U+zexW4D1/SGyemWUCdfB6LE1CNm0MbPLTG4dJJ6RMspmVB6oDu4633iIicnwKO4x2NXAI7/c2W/CGp54MqE4fAD3BW9oAqADsAKYCQ/wZZs2AlsA859xmvGDY3T8fcyPwob+vqUBWD2wQ8LkLaElNp6ujiYjkq7CXq9liZm8CZ5rZpXhf8kGds5kATPDXzjkMDPUDxDIzexv4Ee+K07f5M9HAm1TwKlARbxbadD/9FeB1M0vC69FoWQQRkWJQqGBjZlfh9WRm450H+buZ3eOcezfSFXLOHSafi3w658YCY8OkJwLtw6SnAoMjXUcRETk2hT1nMxo4M2saspnVBWbiTScWEREpUGHP2ZQL+b0LwM5jKCsiImVcYXs2n5jZDOAt//HVeL/UFxEROarCThC4x8yuBM7GO2fzsnPu/UBrdpLRtdFERPJX2J4NzrkpwJQA61Iq6GI4IiJ5FRhszGwfYX5xj9e7cc65aoHUSkRESpUCg41zrmpRVUREREovzSgTEZHAKdiIiEjgFGxERCRwCjYRZmFXNRARKdsUbEREJHAKNiIiEjgFGxERCZyCjYiIBE7BJkJ0bTQRkfwp2ESYro0mIpKXgo2IiAROwUZERAKnYCMiIoFTsBERkcCVuGBjZp3M7DszW2hmiWbWNSRvlJklmdlKM+sbkn6GmS3x88abeafpzSzGzCb76XPNLD6oeruwy/6IiAiUwGAD/BV4xDnXCXjQf4yZtQWGAO2AfsALZhbll3kRGA609G/9/PRbgN3OuRbAM8ATQVdek9FERPIqicHGAVkrgFYHNvn3BwCTnHOHnHNrgSSgq5k1BKo55+Y45xzwb+DykDKv+fffBXpl9XpERKToFLhSZzEZAcwws6fwguFZfnoc8F3Idsl+Wpp/P3d6VpkNAM65dDNLAWoDO0Kf0MyG4/WMaNq0aQSbIiIiUEzBxsxmAg3CZI0GegF3OeemmNlVwCtAb8KPULkC0jlK3pEE514GXgZISEjQyRcRkQgrlmDjnOudX56Z/Ru403/4DvAv/34y0CRk08Z4Q2zJ/v3c6aFlks2sPN6w3K4Trb+IiBybknjOZhNwvn+/J7DKvz8VGOLPMGuGNxFgnnNuM7DPzLr752NuBD4MKTPUvz8I+Nw/rxNxujaaiEj+SuI5m98Az/k9kVT8cynOuWVm9jbwI5AO3Oacy/DL3Aq8ClQEpvs38IbgXjezJLwezZCgK6/pByIieZW4YOOc+wY4I5+8scDYMOmJQPsw6anA4EjXUUREjk1JHEYTEZFSRsFGREQCp2AjIiKBU7AREZHAKdhEiGY+i4jkT8EmwkyX4hQRyUPBRkREAqdgIyIigVOwERGRwCnYiIhI4BRsIiSg63uKiJQKCjYRpgtxiojkpWAjIiKBU7AREZHAKdiIiEjgFGxERCRwCjYRorloIiL5U7AREZHAKdiIiEjgFGxERCRwCjYiIhK4Ygk2ZjbYzJaZWaaZJeTKG2VmSWa20sz6hqSfYWZL/LzxZt5v9c0sxswm++lzzSw+pMxQM1vl34YWWQNFRCSH4urZLAUGAl+FJppZW2AI0A7oB7xgZlF+9ovAcKClf+vnp98C7HbOtQCeAZ7w91ULeAjoBnQFHjKzmkE1SJdGExHJX7EEG+fccufcyjBZA4BJzrlDzrm1QBLQ1cwaAtWcc3Ocd8XLfwOXh5R5zb//LtDL7/X0BT5zzu1yzu0GPuNIgAqM6eJoIiJ5lLRzNnHAhpDHyX5anH8/d3qOMs65dCAFqF3AvvIws+Fmlmhmidu3b49AM0REJFT5oHZsZjOBBmGyRjvnPsyvWJg0V0D68ZbJmejcy8DLAAkJCRoQExGJsMCCjXOu93EUSwaahDxuDGzy0xuHSQ8tk2xm5YHqwC4//YJcZWYfR51EROQElbRhtKnAEH+GWTO8iQDznHObgX1m1t0/H3Mj8GFImayZZoOAz/3zOjOAPmZW058Y0MdPExGRIhZYz6YgZnYF8HegLjDNzBY65/o655aZ2dvAj0A6cJtzLsMvdivwKlARmO7fAF4BXjezJLwezRAA59wuM3sUmO9vN8Y5tyuwRmnwTUQkX8USbJxz7wPv55M3FhgbJj0RaB8mPRUYnM++JgATTqiyx0hz0URE8ippw2giIlIKKdiIiEjgFGxERCRwCjYiIhI4BZsIcZqOJiKSLwWbCNOl0URE8lKwERGRwCnYiIhI4BRsREQkcAo2IiISOAWbCNFKnSIi+VOwiTBNRhMRyUvBRkREAqdgIyIigVOwERGRwBXLejYiIiciLS2N5ORkUlNTi7sqZU5sbCyNGzcmOjr6mMop2ESIJqOJFJ3k5GSqVq1KfHw8pmtEFRnnHDt37iQ5OZlmzZodU1kNo0WY3vgiwUtNTaV27dr6vBUxM6N27drH1aNUsBGRk5ICTfE43tddwUZERAJXLMHGzAab2TIzyzSzhJD0i8xsgZkt8f/2DMk7w09PMrPx5odXM4sxs8l++lwziw8pM9TMVvm3oUXaSBEptXbu3EmnTp3o1KkTDRo0IC4uLvvx4cOHCyybmJjIHXfccUzPFx8fz44dO06kysWuuCYILAUGAv/Mlb4D+JVzbpOZtQdmAHF+3ovAcOA74GOgHzAduAXY7ZxrYWZDgCeAq82sFvAQkIB3/n6BmU11zu0OtmkiUtrVrl2bhQsXAvDwww9TpUoV7r777uz89PR0ypcP//WakJBAQkJC2LzSrFiCjXNuOeQd+3PO/RDycBkQa2YxQC2gmnNujl/u38DleMFmAPCwX+Zd4B9+r6cv8Jlzbpdf5jO8APVWQG0KYrcichSP/HcZP27aG9F9tm1UjYd+1e6Yytx0003UqlWLH374gS5dunD11VczYsQIDh48SMWKFZk4cSKtW7dm9uzZPPXUU3z00Uc8/PDDrF+/njVr1rB+/XpGjBhR6F7Pzz//zLBhw9i+fTt169Zl4sSJNG3alHfeeYdHHnmEqKgoqlevzldffcWyZcu4+eabOXz4MJmZmUyZMoWWLVvyxhtvMH78eA4fPky3bt144YUXALjllltITEzEzBg2bBh33XXXMb+GuZXkqc9XAj845w6ZWRyQHJKXzJEeTxywAcA5l25mKUDt0PQwZQKjc5YiZddPP/3EzJkziYqKYu/evXz11VeUL1+emTNnct999zFlypQ8ZVasWMEXX3zBvn37aN26NbfeemuhfsNy++23c+ONNzJ06FAmTJjAHXfcwQcffMCYMWOYMWMGcXFx7NmzB4CXXnqJO++8k+uuu47Dhw+TkZHB8uXLmTx5Mt9++y3R0dH8/ve/580336Rdu3Zs3LiRpUuXAmTv40QFFmzMbCbQIEzWaOfch0cp2w5vOKxPVlKYzdxR8goqk/v5huMN0dG0adOCqiYiJcyx9kCCNHjwYKKiogBISUlh6NChrFq1CjMjLS0tbJn+/fsTExNDTEwM9erVY+vWrTRu3PiozzVnzhzee+89AG644QbuvfdeAM4++2xuuukmrrrqKgYOHAhAjx49GDt2LMnJyQwcOJCWLVsya9YsFixYwJlnngnAwYMHqVevHr/61a9Ys2YNf/jDH+jfvz99+vQJX4FjFNgEAedcb+dc+zC3owWaxsD7wI3OudV+cjIQ+uo3BjaF5DXxy5YHqgO7QtPDlMld15edcwnOuYS6deseW0NFRHyVK1fOvv/AAw9w4YUXsnTpUv773//m+9uUmJiY7PtRUVGkp6cf13NnnZZ46aWXeOyxx9iwYQOdOnVi586dXHvttUydOpWKFSvSt29fPv/8c5xzDB06lIULF7Jw4UJWrlzJww8/TM2aNVm0aBEXXHABzz//PL/+9a+Pqz65laipz2ZWA5gGjHLOfZuV7pzbDOwzs+7++ZgbgaygNRXImmk2CPjceSdQZgB9zKymmdXE6yXNKJqWiEhZl5KSQlycN3L/6quvRnz/Z511FpMmTQLgzTff5JxzzgFg9erVdOvWjTFjxlCnTh02bNjAmjVraN68OXfccQeXXXYZixcvplevXrz77rts27YNgF27dvHzzz+zY8cOMjMzufLKK3n00Uf5/vvvI1LfYjlnY2ZXAH8H6gLTzGyhc64vcDvQAnjAzB7wN+/jnNsG3Aq8ClTEmxgw3c9/BXjdzJLwejRDAJxzu8zsUWC+v92YrMkCIiJBu/feexk6dChPP/00PXv2PHqBo+jQoQPlynn9g6uuuorx48czbNgwnnzyyewJAgD33HMPq1atwjlHr1696NixI+PGjeONN94gOjqaBg0a8OCDD1KrVi0ee+wx+vTpQ2ZmJtHR0Tz//PNUrFiRm2++mczMTAAef/zxE647gGkWVU4JCQkuMTHxmMvtS01j5JQlDE5ozAWt6wVQMxHJsnz5ck477bTirkaZFe71N7MFzrl853SX5NloJ5WqsdE8f12X4q6GiEiJVKLO2YiISOmkYCMiJyWdAigex/u6K9iIyEknNjaWnTt3KuAUsaz1bGJjY4+5rM7ZiMhJp3HjxiQnJ7N9+/birkqZk7VS57FSsBGRk050dPQxrxQpxUvDaCIiEjgFGxERCZyCjYiIBE5XEMjFzLYDP5/ALurgLQJXlpS1Npe19oLaXFacSJtPcc7leyVjBZsIM7PEgi7ZUBqVtTaXtfaC2lxWBNlmDaOJiEjgFGxERCRwCjaR93JxV6AYlLU2l7X2gtpcVgTWZp2zERGRwKlnIyIigVOwERGRwCnYRIiZ9TOzlWaWZGYji7s+J8LMmpjZF2a23MyWmdmdfnotM/vMzFb5f2uGlBnlt32lmfUNST/DzJb4eePNzIqjTYVhZlFm9oOZfeQ/Lu3trWFm75rZCv9/3aMMtPku/z291MzeMrPY0tZmM5tgZtvMbGlIWsTaaGYxZjbZT59rZvGFqphzTrcTvAFRwGqgOVABWAS0Le56nUB7GgJd/PtVgZ+AtsBfgZF++kjgCf9+W7/NMUAz/7WI8vPmAT0AA6YDFxd3+wpo9x+B/wAf+Y9Le3tfA37t368A1CjNbQbigLVARf/x28BNpa3NwHlAF2BpSFrE2gj8HnjJvz8EmFyoehX3C1Mabv4/ZEbI41HAqOKuVwTb9yFwEbASaOinNQRWhmsvMMN/TRoCK0LSrwH+WdztyaeNjYFZQE+OBJvS3N5q/hev5UovzW2OAzYAtfCueP8R0Kc0thmIzxVsItbGrG38++XxrjhgR6uThtEiI+tNnCXZTzvp+V3kzsBcoL5zbjOA/7eev1l+7Y/z7+dOL4meBe4FMkPSSnN7mwPbgYn+0OG/zKwypbjNzrmNwFPAemAzkOKc+5RS3OYQkWxjdhnnXDqQAtQ+WgUUbCIj3HjtST+n3MyqAFOAEc65vQVtGibNFZBeopjZpcA259yCwhYJk3bStNdXHm+o5UXnXGfgAN7wSn5O+jb75ykG4A0XNQIqm9n1BRUJk3ZStbkQjqeNx9V+BZvISAaahDxuDGwqprpEhJlF4wWaN51z7/nJW82soZ/fENjmp+fX/mT/fu70kuZs4DIzWwdMAnqa2RuU3vaCV9dk59xc//G7eMGnNLe5N7DWObfdOZcGvAecReluc5ZItjG7jJmVB6oDu45WAQWbyJgPtDSzZmZWAe+k2dRirtNx82edvAIsd849HZI1FRjq3x+Kdy4nK32IP0ulGdASmOd31/eZWXd/nzeGlCkxnHOjnHONnXPxeP+7z51z11NK2wvgnNsCbDCz1n5SL+BHSnGb8YbPuptZJb+uvYDllO42Z4lkG0P3NQjv83L0nl1xn8gqLTfgErxZW6uB0cVdnxNsyzl43eLFwEL/dgneuOwsYJX/t1ZImdF+21cSMjMHSACW+nn/oBAnEou57RdwZIJAqW4v0AlI9P/PHwA1y0CbHwFW+PV9HW8WVqlqM/AW3jmpNLxeyC2RbCMQC7wDJOHNWGtemHrpcjUiIhI4DaOJiEjgFGxERCRwCjYiIhI4BRsREQmcgo2IiAROwUakFDGzC8y/arVISaJgIyIigVOwESkGZna9mc0zs4Vm9k/z1tLZb2Z/M7PvzWyWmdX1t+1kZt+Z2WIzez9rLRIza2FmM81skV/mVH/3VezIOjVvlqS1VqTsUrARKWJmdhpwNXC2c64TkAFcB1QGvnfOdQG+BB7yi/wb+LNzrgOwJCT9TeB551xHvGt8bfbTOwMj8NYqaY537TeRYlW+uCsgUgb1As4A5vudjop4F0bMBCb727wBvGdm1YEazrkv/fTXgHfMrCoQ55x7H8A5lwrg72+ecy7Zf7wQb22TbwJvlUgBFGxEip4BrznnRuVINHsg13YFXUuqoKGxQyH3M9DnXEoADaOJFL1ZwCAzqwfZ68Ofgvd5HORvcy3wjXMuBdhtZuf66TcAXzpvfaFkM7vc30eMmVUqykaIHAsd8YgUMefcj2Z2P/CpmZXDuzrvbXgLmLUzswV4qx9e7RcZCrzkB5M1wM1++g3AP81sjL+PwUXYDJFjoqs+i5QQZrbfOVeluOshEgQNo4mISODUsxERkcCpZyMiIoFTsBERkcAp2IiISOAUbEREJHAKNiIiErj/B98KwCip8l9KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model.losses, label = \"Train Losses\")\n",
    "plt.title(\"Losses\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"losses\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Communication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpret your result:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Picking feature: from cross validation, the MSE is quite more lower than picking other features, also work well in minibatch.\n",
    "2. Loss (error): from the plot, the loss is quite good because it is decreasing signicifantly and near around zero, although the beginning is negative value.\n",
    "3. fluctuating: The result is fluctuate a bit, I think because of using minibatch in cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
